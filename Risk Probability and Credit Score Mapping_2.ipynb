{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelayAbAb/AI-Powered-Credit-Scoring-Model-/blob/Refactor-Codebase-for-Modularity-and-Maintainability/Risk%20Probability%20and%20Credit%20Score%20Mapping_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYV91hbKwP2J"
      },
      "source": [
        "Colab notebooks execute code on Google's cloud servers, meaning you can leverage the power of Google hardware, including [GPUs and TPUs](#using-accelerated-hardware), regardless of the power of your machine. All you need is a browser.\n",
        "\n",
        "For example, if you find yourself waiting for **pandas** code to finish running and want to go faster, you can switch to a GPU Runtime and use libraries like [RAPIDS cuDF](https://rapids.ai/cudf-pandas) that provide zero-code-change acceleration."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary dependencies\n",
        "!pip install -q seaborn matplotlib scikit-learn gdown\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import gdown  # This will allow downloading from Google Drive\n",
        "\n",
        "# Step 3: Download the file using the shared Google Drive link\n",
        "\n",
        "# Shared link: https://drive.google.com/file/d/1OpwfxIO8aeDDsdSEgGrnyn1F6MFw4O6x/view?usp=sharing\n",
        "# Extract the file ID from the link (the ID is the part between /d/ and /view)\n",
        "file_id = '1OpwfxIO8aeDDsdSEgGrnyn1F6MFw4O6x'\n",
        "\n",
        "# Construct the download URL\n",
        "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(download_url, 'data.csv', quiet=False)\n",
        "\n",
        "# Step 4: Load the CSV file from the local directory\n",
        "df = pd.read_csv('data.csv')  # The file will be downloaded to the current directory\n",
        "df.dataframeName = 'data.csv'\n",
        "\n",
        "# Step 5: Check the shape of the data\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns in {df.dataframeName}')\n",
        "\n",
        "# Step 6: Take a quick look at the data\n",
        "print(df.head(5))\n",
        "\n",
        "# Step 7: Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Filter out non-numeric columns for correlation and other numerical operations\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Define output directory in Google Drive\n",
        "output_dir = '/content/drive/MyDrive/1fINHoR_jYkPkHB-7HPm1fxQqIxeFOKnR/EDA_Results/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Distribution of numeric columns - Save the plot to Google Drive\n",
        "def plotPerColumnDistribution(df, nRows, nCols):\n",
        "    df.hist(figsize=(nRows, nCols))\n",
        "    plt.savefig(os.path.join(output_dir, 'distribution_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "plotPerColumnDistribution(numeric_df, 10, 5)\n",
        "\n",
        "# Correlation matrix of numeric columns - Save the plot to Google Drive\n",
        "def plotCorrelationMatrix(df, nRows):\n",
        "    corr = df.corr()\n",
        "    plt.figure(figsize=(nRows, nRows))\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "    plt.savefig(os.path.join(output_dir, 'correlation_matrix.png'))\n",
        "    plt.close()\n",
        "\n",
        "plotCorrelationMatrix(numeric_df, 8)\n",
        "\n",
        "# Scatter and density plots (only for numeric columns) - Save the plot to Google Drive\n",
        "def plotScatterMatrix(df, nRows, nCols):\n",
        "    sns.pairplot(df, height=2.5)\n",
        "    plt.savefig(os.path.join(output_dir, 'scatter_matrix.png'))\n",
        "    plt.close()\n",
        "\n",
        "plotScatterMatrix(numeric_df, 12, 10)\n",
        "\n",
        "# Save the processed data as CSV to Google Drive\n",
        "output_csv_path = os.path.join(output_dir, 'processed_data.csv')\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Conclusion message\n",
        "print(f\"All output files have been saved to: {output_dir}\")\n",
        "print(\"This concludes the exploratory data analysis!\")\n"
      ],
      "metadata": {
        "id": "zE4NZl-ik9wh",
        "outputId": "267694c2-8116-4476-cf30-c0876946602a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1OpwfxIO8aeDDsdSEgGrnyn1F6MFw4O6x\n",
            "To: /content/data.csv\n",
            "100%|██████████| 17.4M/17.4M [00:00<00:00, 211MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 95662 rows and 16 columns in data.csv\n",
            "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
            "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
            "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
            "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
            "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
            "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
            "\n",
            "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
            "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
            "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
            "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
            "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
            "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
            "\n",
            "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
            "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
            "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
            "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
            "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
            "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
            "\n",
            "   PricingStrategy  FraudResult  \n",
            "0                2            0  \n",
            "1                2            0  \n",
            "2                2            0  \n",
            "3                2            0  \n",
            "4                2            0  \n",
            "All output files have been saved to: /content/drive/MyDrive/1fINHoR_jYkPkHB-7HPm1fxQqIxeFOKnR/EDA_Results/\n",
            "This concludes the exploratory data analysis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Step 1: Download the dataset from Google Drive\n",
        "file_id = '1OpwfxIO8aeDDsdSEgGrnyn1F6MFw4O6x'\n",
        "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "gdown.download(download_url, 'data.csv', quiet=False)\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Check for missing values and data types\n",
        "print(\"Data types:\\n\", data.dtypes)\n",
        "print(\"Missing values:\\n\", data.isnull().sum())\n",
        "\n",
        "# Step 3: Split the data into features (X) and target (y)\n",
        "# We assume 'FraudResult' is the target variable for binary classification\n",
        "X = data.drop(columns=['FraudResult', 'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'TransactionStartTime'])\n",
        "y = data['FraudResult']\n",
        "\n",
        "# Step 4: Split the data into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Step 5: Define preprocessing steps for numerical and categorical features\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Numerical features:\", numerical_features)\n",
        "print(\"Categorical features:\", categorical_features)\n",
        "\n",
        "# Create a ColumnTransformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('num', StandardScaler(), numerical_features),\n",
        "                  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Step 6: Define models with increased max_iter for Logistic Regression\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=5000),  # Increased max_iter\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning parameters\n",
        "param_grid = {\n",
        "    'Logistic Regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'model__solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_depth': [None, 10, 20, 30],\n",
        "        'model__min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'model__max_depth': [3, 5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 7: Train and evaluate each model\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Create a pipeline with preprocessing and model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('model', model)])\n",
        "\n",
        "    # Perform hyperparameter tuning\n",
        "    if model_name == 'Logistic Regression':\n",
        "        grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='f1', verbose=1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    else:\n",
        "        grid_search = RandomizedSearchCV(pipeline, param_grid[model_name], n_iter=10, cv=5, scoring='f1', random_state=42)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best model and its score\n",
        "    best_model = grid_search.best_estimator_\n",
        "    results[model_name] = {\n",
        "        'best_model': best_model,\n",
        "        'best_score': grid_search.best_score_,\n",
        "    }\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    results[model_name]['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    results[model_name]['precision'] = precision_score(y_test, y_pred)\n",
        "    results[model_name]['recall'] = recall_score(y_test, y_pred)\n",
        "    results[model_name]['f1_score'] = f1_score(y_test, y_pred)\n",
        "    results[model_name]['roc_auc'] = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    # Step 8: Confusion Matrix Visualization\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Fraud', 'Fraud'])\n",
        "\n",
        "    # Save confusion matrix plot\n",
        "    output_folder = '/content/drive/MyDrive/your_folder_path_here/'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cm_output_path = os.path.join(output_folder, f\"cm_{model_name}.jpg\")\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.savefig(cm_output_path)\n",
        "    plt.close()\n",
        "\n",
        "# Step 9: Prepare data for plotting\n",
        "metric_names = ['Best CV Score', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']\n",
        "metric_values = {model: [results[model]['best_score'],\n",
        "                         results[model]['accuracy'],\n",
        "                         results[model]['precision'],\n",
        "                         results[model]['recall'],\n",
        "                         results[model]['f1_score'],\n",
        "                         results[model]['roc_auc']] for model in models.keys()}\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "width = 0.15  # Width of the bars\n",
        "x = np.arange(len(metric_names))  # the label locations\n",
        "\n",
        "for i, model in enumerate(models.keys()):\n",
        "    ax.bar(x + i * width, metric_values[model], width, label=model)\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Training and Evaluation Metrics')\n",
        "ax.set_xticks(x + width / 2)\n",
        "ax.set_xticklabels(metric_names)\n",
        "ax.legend()\n",
        "\n",
        "# Save the plot as JPG in the specified local folder\n",
        "output_plot_path = os.path.join(output_folder, \"model_evaluation_metrics.jpg\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_plot_path)\n",
        "plt.close()\n",
        "\n",
        "# Step 10: Save the results to a CSV file\n",
        "output_results_path = os.path.join(output_folder, \"model_results.csv\")\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "results_df.to_csv(output_results_path)\n",
        "\n",
        "print(\"Model evaluation metrics and results saved successfully.\")\n"
      ],
      "metadata": {
        "id": "_h4G3y0Ms7YF",
        "outputId": "269653da-abb7-4d13-a169-c344cca0c6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1OpwfxIO8aeDDsdSEgGrnyn1F6MFw4O6x\n",
            "To: /content/data.csv\n",
            "100%|██████████| 17.4M/17.4M [00:00<00:00, 110MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types:\n",
            " TransactionId            object\n",
            "BatchId                  object\n",
            "AccountId                object\n",
            "SubscriptionId           object\n",
            "CustomerId               object\n",
            "CurrencyCode             object\n",
            "CountryCode               int64\n",
            "ProviderId               object\n",
            "ProductId                object\n",
            "ProductCategory          object\n",
            "ChannelId                object\n",
            "Amount                  float64\n",
            "Value                     int64\n",
            "TransactionStartTime     object\n",
            "PricingStrategy           int64\n",
            "FraudResult               int64\n",
            "dtype: object\n",
            "Missing values:\n",
            " TransactionId           0\n",
            "BatchId                 0\n",
            "AccountId               0\n",
            "SubscriptionId          0\n",
            "CustomerId              0\n",
            "CurrencyCode            0\n",
            "CountryCode             0\n",
            "ProviderId              0\n",
            "ProductId               0\n",
            "ProductCategory         0\n",
            "ChannelId               0\n",
            "Amount                  0\n",
            "Value                   0\n",
            "TransactionStartTime    0\n",
            "PricingStrategy         0\n",
            "FraudResult             0\n",
            "dtype: int64\n",
            "Numerical features: ['CountryCode', 'Amount', 'Value', 'PricingStrategy']\n",
            "Categorical features: ['CurrencyCode', 'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId']\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Model evaluation metrics and results saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Mock dataset for testing (you should adapt it to your actual data)\n",
        "np.random.seed(42)\n",
        "df_cleaned = pd.DataFrame({\n",
        "    'ProductCategory': np.random.choice(['A', 'B', 'C', 'D'], size=1000),\n",
        "    'Recency': np.random.randint(1, 365, size=1000),  # Days since last purchase\n",
        "    'Frequency': np.random.randint(1, 50, size=1000),  # Number of transactions\n",
        "    'Monetary': np.random.randint(100, 5000, size=1000),  # Monetary value of transactions\n",
        "})\n",
        "\n",
        "# Mock binary target variable for demonstration (1 for good, 0 for bad)\n",
        "df_cleaned['Default'] = np.random.choice([0, 1], size=len(df_cleaned), p=[0.7, 0.3])\n",
        "\n",
        "# Function to calculate WoE for categorical features\n",
        "def calculate_woe(data, target, feature):\n",
        "    \"\"\"\n",
        "    Function to calculate Weight of Evidence (WoE) for categorical variables.\n",
        "\n",
        "    Caution: Ensure that the feature has enough data points per category.\n",
        "    Small sample sizes for some categories can lead to unreliable WoE values.\n",
        "    \"\"\"\n",
        "    # Create a DataFrame for WoE calculation\n",
        "    woe_df = data.groupby(feature)[target].agg(['count', 'sum']).reset_index()\n",
        "    woe_df.columns = [feature, 'Total', 'Good']\n",
        "\n",
        "    # Calculate Bad\n",
        "    woe_df['Bad'] = woe_df['Total'] - woe_df['Good']\n",
        "\n",
        "    # Calculate proportions\n",
        "    total_good = woe_df['Good'].sum()\n",
        "    total_bad = woe_df['Bad'].sum()\n",
        "\n",
        "    # Calculate WoE\n",
        "    woe_df['Good_Percentage'] = woe_df['Good'] / total_good\n",
        "    woe_df['Bad_Percentage'] = woe_df['Bad'] / total_bad\n",
        "    woe_df['WoE'] = np.log(woe_df['Good_Percentage'] / woe_df['Bad_Percentage']).replace([-np.inf, np.inf], 0)\n",
        "\n",
        "    return woe_df[[feature, 'WoE']]\n",
        "\n",
        "# Function to apply WoE binning for continuous features (e.g., Recency, Frequency, Monetary)\n",
        "def binning_woe(data, target, feature, bins=5):\n",
        "    \"\"\"\n",
        "    Function to bin continuous features and calculate WoE for each bin.\n",
        "\n",
        "    Caution: Binning can be a very subjective process. The choice of the number of bins\n",
        "    and bin edges can significantly impact the results. Consider domain knowledge when\n",
        "    defining the binning strategy.\n",
        "    \"\"\"\n",
        "    # Bin continuous variable into intervals (e.g., Recency, Frequency, Monetary)\n",
        "    data['bin'] = pd.cut(data[feature], bins, right=False)\n",
        "\n",
        "    # Calculate WoE for each bin\n",
        "    return calculate_woe(data, target, 'bin')\n",
        "\n",
        "# Apply WoE Binning to 'ProductCategory' (categorical feature)\n",
        "woe_product_category = calculate_woe(df_cleaned, 'Default', 'ProductCategory')\n",
        "\n",
        "# Merge WoE values back to the original DataFrame\n",
        "df_cleaned = df_cleaned.merge(woe_product_category, on='ProductCategory', how='left')\n",
        "df_cleaned.rename(columns={'WoE': 'WoE_ProductCategory'}, inplace=True)\n",
        "\n",
        "# Apply WoE Binning to continuous features: 'Recency', 'Frequency', 'Monetary'\n",
        "woe_recency = binning_woe(df_cleaned, 'Default', 'Recency')\n",
        "woe_frequency = binning_woe(df_cleaned, 'Default', 'Frequency')\n",
        "woe_monetary = binning_woe(df_cleaned, 'Default', 'Monetary')\n",
        "\n",
        "# Merge WoE values for Recency, Frequency, and Monetary back to the DataFrame\n",
        "# Keep the 'bin' column for subsequent merges (no drop for the first two merges)\n",
        "df_cleaned = df_cleaned.merge(woe_recency, left_on='bin', right_on='bin', how='left')  # Do not drop 'bin' yet\n",
        "df_cleaned.rename(columns={'WoE': 'WoE_Recency'}, inplace=True)\n",
        "\n",
        "df_cleaned = df_cleaned.merge(woe_frequency, left_on='bin', right_on='bin', how='left')  # Do not drop 'bin' yet\n",
        "df_cleaned.rename(columns={'WoE': 'WoE_Frequency'}, inplace=True)\n",
        "\n",
        "# Now, drop 'bin' after the last merge for Monetary (the last step)\n",
        "df_cleaned = df_cleaned.merge(woe_monetary, left_on='bin', right_on='bin', how='left').drop('bin', axis=1)\n",
        "df_cleaned.rename(columns={'WoE': 'WoE_Monetary'}, inplace=True)\n",
        "\n",
        "# Display the first few rows of the modified DataFrame with WoE values\n",
        "print(df_cleaned[['ProductCategory', 'WoE_ProductCategory', 'Recency', 'WoE_Recency', 'Frequency', 'WoE_Frequency', 'Monetary', 'WoE_Monetary']].head())\n",
        "\n",
        "# Save the modified DataFrame with WoE values\n",
        "woe_output_path = r\"C:\\Users\\User\\Desktop\\woe_data.csv\"\n",
        "df_cleaned.to_csv(woe_output_path, index=False)\n",
        "\n",
        "print(f\"Woe data saved as {woe_output_path}\")\n",
        "\n",
        "# Step 2: Define a Default Estimator (proxy variable) based on the WoE values and RFMS\n",
        "# Create a composite score from the WoE values for Recency, Frequency, and Monetary\n",
        "df_cleaned['Risk_Score'] = df_cleaned['WoE_Recency'] + df_cleaned['WoE_Frequency'] + df_cleaned['WoE_Monetary']\n",
        "\n",
        "# Create a 'Risk' label: High risk (bad) if Risk_Score < threshold, Low risk (good) otherwise\n",
        "threshold = df_cleaned['Risk_Score'].median()  # Median can be a simple threshold, or use another strategy\n",
        "df_cleaned['Risk'] = np.where(df_cleaned['Risk_Score'] < threshold, 1, 0)  # 1 for high risk (bad), 0 for low risk (good)\n",
        "\n",
        "# Display the Risk segmentation\n",
        "print(df_cleaned[['Recency', 'Frequency', 'Monetary', 'Risk_Score', 'Risk']].head())\n",
        "\n",
        "# Additional caution about RFMS:\n",
        "# RFMS (Recency, Frequency, Monetary) is a common approach in marketing and credit scoring.\n",
        "# Ensure that your RFMS model aligns with industry best practices (e.g., Basel II Capital Accord)\n",
        "# and consult financial regulations to meet compliance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hocNkJbvBSPj",
        "outputId": "68efa7c4-4ba7-4888-fbdc-48ab4814153d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ProductCategory  WoE_ProductCategory  Recency  WoE_Recency  Frequency  \\\n",
            "0               C            -0.020074      145          NaN         29   \n",
            "1               D             0.091892      201          NaN         12   \n",
            "2               A            -0.059567      212          NaN         36   \n",
            "3               C            -0.020074      220          NaN         35   \n",
            "4               C            -0.020074      240          NaN         12   \n",
            "\n",
            "   WoE_Frequency  Monetary  WoE_Monetary  \n",
            "0            NaN      2330      0.072193  \n",
            "1            NaN      4140     -0.020298  \n",
            "2            NaN      4683     -0.020298  \n",
            "3            NaN      3797      0.043083  \n",
            "4            NaN      2937      0.072193  \n",
            "Woe data saved as C:\\Users\\User\\Desktop\\woe_data.csv\n",
            "   Recency  Frequency  Monetary  Risk_Score  Risk\n",
            "0      145         29      2330         NaN     0\n",
            "1      201         12      4140         NaN     0\n",
            "2      212         36      4683         NaN     0\n",
            "3      220         35      3797         NaN     0\n",
            "4      240         12      2937         NaN     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df_cleaned = pd.read_csv('data.csv')\n",
        "\n",
        "# Step 2: Split the data into features (X) and target (y)\n",
        "X = df_cleaned.drop(columns=['FraudResult', 'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'TransactionStartTime'])\n",
        "y = df_cleaned['FraudResult']\n",
        "\n",
        "# Step 3: Split the data into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Step 4: Preprocessing\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Create a ColumnTransformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('num', StandardScaler(), numerical_features),\n",
        "                  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Step 5: Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=5000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning parameters\n",
        "param_grid = {\n",
        "    'Logistic Regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'model__solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_depth': [None, 10, 20, 30],\n",
        "        'model__min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'model__max_depth': [3, 5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 6: Train and evaluate each model\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Create a pipeline with preprocessing and model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('model', model)])\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
        "    if model_name == 'Logistic Regression':\n",
        "        grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='f1', verbose=1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    else:\n",
        "        grid_search = RandomizedSearchCV(pipeline, param_grid[model_name], n_iter=10, cv=5, scoring='f1', random_state=42)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best model and its score\n",
        "    best_model = grid_search.best_estimator_\n",
        "    results[model_name] = {\n",
        "        'best_model': best_model,\n",
        "        'best_score': grid_search.best_score_\n",
        "    }\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    results[model_name]['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    results[model_name]['precision'] = precision_score(y_test, y_pred)\n",
        "    results[model_name]['recall'] = recall_score(y_test, y_pred)\n",
        "    results[model_name]['f1_score'] = f1_score(y_test, y_pred)\n",
        "    results[model_name]['roc_auc'] = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    # Confusion Matrix Visualization\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Fraud', 'Fraud'])\n",
        "\n",
        "    # Save confusion matrix plot\n",
        "    output_folder = '/content/drive/MyDrive/your_folder_path_here/'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cm_output_path = os.path.join(output_folder, f\"cm_{model_name}.jpg\")\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.savefig(cm_output_path)\n",
        "    plt.close()\n",
        "\n",
        "# Step 7: Risk Probability and Credit Score Mapping\n",
        "\n",
        "# Get the predicted probabilities for the test set\n",
        "y_pred_prob = best_model.predict_proba(X_test)[:, 1]  # Probability for the positive class (Fraud/High Risk)\n",
        "\n",
        "# Categorize customers into risk groups based on probabilities\n",
        "risk_groups = pd.cut(y_pred_prob, bins=[0, 0.2, 0.4, 0.6, 1.0], labels=['Very Low Risk', 'Low Risk', 'Moderate Risk', 'High Risk'])\n",
        "\n",
        "# Map risk groups to credit score\n",
        "# Assuming that higher risk corresponds to a lower credit score\n",
        "credit_score_mapping = {\n",
        "    'Very Low Risk': 800,  # Best credit score\n",
        "    'Low Risk': 700,\n",
        "    'Moderate Risk': 600,\n",
        "    'High Risk': 500  # Worst credit score\n",
        "}\n",
        "\n",
        "# Map the risk groups to credit scores\n",
        "credit_scores = risk_groups.map(credit_score_mapping)\n",
        "\n",
        "# Add the risk group and credit score columns to the dataframe\n",
        "df_cleaned.loc[X_test.index, 'Risk_Group'] = risk_groups\n",
        "df_cleaned.loc[X_test.index, 'Credit_Score'] = credit_scores\n",
        "\n",
        "# Display the first few rows of the data with risk groups and credit scores\n",
        "print(df_cleaned[['CustomerId', 'Risk_Group', 'Credit_Score']].head())\n",
        "\n",
        "# Save the data with risk groups and credit scores\n",
        "output_risk_path = os.path.join(output_folder, 'customer_risk_scores.csv')\n",
        "df_cleaned[['CustomerId', 'Risk_Group', 'Credit_Score']].to_csv(output_risk_path, index=False)\n",
        "\n",
        "print(f\"Customer risk data with credit scores saved at {output_risk_path}\")\n",
        "\n",
        "# Step 8: Plot the Risk Probability Distribution\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_pred_prob, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Risk Probability Distribution', fontsize=16)\n",
        "plt.xlabel('Risk Probability', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "# Save the histogram as a .jpg image\n",
        "output_hist_path = os.path.join(output_folder, 'risk_probability_distribution.jpg')\n",
        "plt.savefig(output_hist_path, format='jpg', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f\"Risk probability distribution plot saved at {output_hist_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0tSnErbIhbA",
        "outputId": "a989a6cd-87c3-4d8c-b069-061c4ec3f494"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "        CustomerId     Risk_Group Credit_Score\n",
            "0  CustomerId_4406            NaN          NaN\n",
            "1  CustomerId_4406            NaN          NaN\n",
            "2  CustomerId_4683  Very Low Risk          800\n",
            "3   CustomerId_988            NaN          NaN\n",
            "4   CustomerId_988            NaN          NaN\n",
            "Customer risk data with credit scores saved at /content/drive/MyDrive/your_folder_path_here/customer_risk_scores.csv\n",
            "Risk probability distribution plot saved at /content/drive/MyDrive/your_folder_path_here/risk_probability_distribution.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Modify the path to your actual file location\n",
        "\n",
        "# If you're using Google Colab or Jupyter with Google Drive:\n",
        "df_cleaned = pd.read_csv('/content/drive/MyDrive/your_folder_path_here/data.csv')\n",
        "\n",
        "# If the file is in the same directory as your script, use:\n",
        "# df_cleaned = pd.read_csv('data.csv')\n",
        "\n",
        "# Alternatively, you can specify the full path of the dataset if it's in a different folder:\n",
        "# df_cleaned = pd.read_csv('/path/to/your/folder/data.csv')\n",
        "\n",
        "# Step 2: Split the data into features (X) and target (y)\n",
        "X = df_cleaned.drop(columns=['FraudResult', 'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'TransactionStartTime'])\n",
        "y = df_cleaned['FraudResult']\n",
        "\n",
        "# Step 3: Split the data into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Step 4: Preprocessing\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Create a ColumnTransformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('num', StandardScaler(), numerical_features),\n",
        "                  ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Step 5: Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=5000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning parameters\n",
        "param_grid = {\n",
        "    'Logistic Regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'model__solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_depth': [None, 10, 20, 30],\n",
        "        'model__min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'model__max_depth': [3, 5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 6: Train and evaluate each model\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    # Create a pipeline with preprocessing and model\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                ('model', model)])\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
        "    if model_name == 'Logistic Regression':\n",
        "        grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='f1', verbose=1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "    else:\n",
        "        grid_search = RandomizedSearchCV(pipeline, param_grid[model_name], n_iter=10, cv=5, scoring='f1', random_state=42)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Store the best model and its score\n",
        "    best_model = grid_search.best_estimator_\n",
        "    results[model_name] = {\n",
        "        'best_model': best_model,\n",
        "        'best_score': grid_search.best_score_\n",
        "    }\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    results[model_name]['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    results[model_name]['precision'] = precision_score(y_test, y_pred)\n",
        "    results[model_name]['recall'] = recall_score(y_test, y_pred)\n",
        "    results[model_name]['f1_score'] = f1_score(y_test, y_pred)\n",
        "    results[model_name]['roc_auc'] = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    # Confusion Matrix Visualization\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Fraud', 'Fraud'])\n",
        "\n",
        "    # Save confusion matrix plot\n",
        "    output_folder = '/content/drive/MyDrive/your_folder_path_here/'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cm_output_path = os.path.join(output_folder, f\"cm_{model_name}.jpg\")\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.savefig(cm_output_path)\n",
        "    plt.close()\n",
        "\n",
        "# Step 7: Risk Probability and Credit Score Mapping\n",
        "\n",
        "# Get the predicted probabilities for the test set\n",
        "best_model = results['Random Forest']['best_model']  # Assume RandomForest performs best, adjust if needed\n",
        "y_pred_prob = best_model.predict_proba(X_test)[:, 1]  # Probability for the positive class (Fraud/High Risk)\n",
        "\n",
        "# Categorize customers into risk groups based on probabilities\n",
        "risk_groups = pd.cut(y_pred_prob, bins=[0, 0.2, 0.4, 0.6, 1.0], labels=['Very Low Risk', 'Low Risk', 'Moderate Risk', 'High Risk'])\n",
        "\n",
        "# Map risk groups to credit score\n",
        "credit_score_mapping = {\n",
        "    'Very Low Risk': 800,  # Best credit score\n",
        "    'Low Risk': 700,\n",
        "    'Moderate Risk': 600,\n",
        "    'High Risk': 500  # Worst credit score\n",
        "}\n",
        "\n",
        "# Map the risk groups to credit scores\n",
        "credit_scores = risk_groups.map(credit_score_mapping)\n",
        "\n",
        "# Add the risk group and credit score columns to the dataframe\n",
        "df_cleaned.loc[X_test.index, 'Risk_Group'] = risk_groups\n",
        "df_cleaned.loc[X_test.index, 'Credit_Score'] = credit_scores\n",
        "\n",
        "# Display the first few rows of the data with risk groups and credit scores\n",
        "print(df_cleaned[['CustomerId', 'Risk_Group', 'Credit_Score']].head())\n",
        "\n",
        "# Save the data with risk groups and credit scores\n",
        "output_risk_path = os.path.join(output_folder, 'customer_risk_scores.csv')\n",
        "df_cleaned[['CustomerId', 'Risk_Group', 'Credit_Score']].to_csv(output_risk_path, index=False)\n",
        "\n",
        "print(f\"Customer risk data with credit scores saved at {output_risk_path}\")\n",
        "\n",
        "\n",
        "# Step 8: Summarize the output: Risk Groups and Statistics\n",
        "\n",
        "# Group by risk group and summarize\n",
        "risk_summary = df_cleaned[['CustomerId', 'Risk_Group', 'Credit_Score']].groupby('Risk_Group').agg(\n",
        "    count=('CustomerId', 'count'),\n",
        "    # Convert 'Credit_Score' to numeric before calculating the mean to avoid errors\n",
        "    avg_credit_score=('Credit_Score', lambda x: pd.to_numeric(x, errors='coerce').mean()),\n",
        "    min_credit_score=('Credit_Score', 'min'),\n",
        "    max_credit_score=('Credit_Score', 'max'),\n",
        "    risk_probability_range=('Credit_Score', lambda x: (x.min(), x.max()))\n",
        ").reset_index()\n",
        "\n",
        "# Display the risk group summary\n",
        "print(\"\\nRisk Group Summary:\")\n",
        "print(risk_summary)\n",
        "\n",
        "# Optionally, you can also save this summary to a CSV file for further use\n",
        "output_summary_path = '/content/drive/MyDrive/your_folder_path_here/risk_group_summary.csv'\n",
        "risk_summary.to_csv(output_summary_path, index=False)\n",
        "\n",
        "print(f\"Risk group summary saved at {output_summary_path}\")\n",
        "\n",
        "# ... (rest of the code remains the same) ...\n",
        "\n",
        "\n",
        "# Step 9: Plot the Risk Probability Distribution\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_pred_prob, bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Risk Probability Distribution', fontsize=16)\n",
        "plt.xlabel('Risk Probability', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "\n",
        "# Save the histogram as a .jpg image\n",
        "output_hist_path = os.path.join(output_folder, 'risk_probability_distribution.jpg')\n",
        "plt.savefig(output_hist_path, format='jpg', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f\"Risk probability distribution plot saved at {output_hist_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBfnaLsnQXhQ",
        "outputId": "063d969e-0a3c-46f7-d2fc-7c26ba883bf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "        CustomerId     Risk_Group Credit_Score\n",
            "0  CustomerId_4406            NaN          NaN\n",
            "1  CustomerId_4406            NaN          NaN\n",
            "2  CustomerId_4683  Very Low Risk          800\n",
            "3   CustomerId_988            NaN          NaN\n",
            "4   CustomerId_988            NaN          NaN\n",
            "Customer risk data with credit scores saved at /content/drive/MyDrive/your_folder_path_here/customer_risk_scores.csv\n",
            "\n",
            "Risk Group Summary:\n",
            "      Risk_Group  count avg_credit_score min_credit_score max_credit_score  \\\n",
            "0  Very Low Risk  26042              800              800              800   \n",
            "1       Low Risk     12              700              700              700   \n",
            "2  Moderate Risk      9              600              600              600   \n",
            "3      High Risk     52              500              500              500   \n",
            "\n",
            "  risk_probability_range  \n",
            "0             (800, 800)  \n",
            "1             (700, 700)  \n",
            "2             (600, 600)  \n",
            "3             (500, 500)  \n",
            "Risk group summary saved at /content/drive/MyDrive/your_folder_path_here/risk_group_summary.csv\n",
            "Risk probability distribution plot saved at /content/drive/MyDrive/your_folder_path_here/risk_probability_distribution.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Sample Data (replace this with your actual dataset)\n",
        "# Assuming 'df_cleaned' is your dataset and 'FraudResult' is your target variable\n",
        "# X = df_cleaned.drop(columns=['FraudResult', 'other_columns'])\n",
        "# y = df_cleaned['FraudResult']\n",
        "\n",
        "# For illustration, I'll use dummy data (replace it with your actual data)\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a model pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Optional preprocessing step (scaling)\n",
        "    ('model', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a .joblib file\n",
        "joblib.dump(pipeline, 'credit_risk_model.joblib')\n",
        "\n",
        "print(\"Model saved as 'credit_risk_model.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVfDlGsJaZof",
        "outputId": "3845306e-8fef-469d-b3f2-80524efacda5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'credit_risk_model.joblib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6HnmqeCb_RI",
        "outputId": "ceeb0c11-833d-4db3-ce04-c2e0301b9e7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.115.5 starlette-0.41.2\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.12.2)\n",
            "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn\n",
            "Successfully installed uvicorn-0.32.0\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WotBFQ0FcM-C"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}